{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Neural Network Model\n",
    "class SentimentAnalysisModel_global(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SentimentAnalysisModel_global, self).__init__()\n",
    "        self.fc1 = nn.Linear(10000, 2)\n",
    "        self.fc2 = nn.Linear(2, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        # Replace BatchNorm with GroupNorm\n",
    "        self.groupnorm = nn.GroupNorm(1, 2)  # GroupNorm with 1 group and 2 channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.groupnorm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting fixed seed for reproducibility of the random weights and biases\n",
    "torch.manual_seed(19)\n",
    "\n",
    "# Initialized global model with random weights and biases\n",
    "model_global = SentimentAnalysisModel_global()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[ 0.0094, -0.0060,  0.0076,  ..., -0.0070,  0.0011,  0.0049],\n",
       "                      [-0.0077, -0.0098, -0.0039,  ..., -0.0005, -0.0024, -0.0059]])),\n",
       "             ('fc1.bias', tensor([0.0017, 0.0014])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 0.5814,  0.0490],\n",
       "                      [-0.1220, -0.4694],\n",
       "                      [ 0.4106, -0.6040]])),\n",
       "             ('fc2.bias', tensor([-0.5295,  0.3521,  0.5361])),\n",
       "             ('groupnorm.weight', tensor([1., 1.])),\n",
       "             ('groupnorm.bias', tensor([0., 0.]))])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the object containing the randomn weights and biases for this global model\n",
    "model_global.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save global model weights and biases\n",
    "torch.save(model_global.state_dict(), 'global_parameters.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "node1_df = pd.read_csv('node1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leo_c\\anaconda3\\lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\leo_c\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('_module.fc1.weight',\n",
       "              tensor([[ 0.3400,  0.1648, -0.0120,  ...,  0.2103,  0.2675,  0.1745],\n",
       "                      [ 0.2891,  0.2614, -0.1232,  ..., -0.0202,  0.5096,  0.6269]])),\n",
       "             ('_module.fc1.bias', tensor([-0.1213,  0.3632])),\n",
       "             ('_module.fc2.weight',\n",
       "              tensor([[ 0.5619,  0.0126],\n",
       "                      [ 0.5260, -0.4331],\n",
       "                      [ 0.6782, -0.5148]])),\n",
       "             ('_module.fc2.bias', tensor([-0.4159,  0.0047,  0.6919])),\n",
       "             ('_module.groupnorm.weight', tensor([0.6429, 1.2070])),\n",
       "             ('_module.groupnorm.bias', tensor([ 0.2980, -0.3828]))])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import Word2Vec\n",
    "from opacus import PrivacyEngine\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Function to check and balance the dataset\n",
    "def balance_dataset(df):\n",
    "    sentiment_counts = df['Sentiment'].value_counts()\n",
    "    if any(sentiment_counts != sentiment_counts[0]):\n",
    "        ros = RandomOverSampler(random_state=42)\n",
    "        df_balanced, _ = ros.fit_resample(df, df['Sentiment'])\n",
    "        return df_balanced\n",
    "    return df\n",
    "\n",
    "# Text preprocessing steps\n",
    "def preprocess_text(text):\n",
    "    # Text cleaning\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Normalization (using lemmatization here)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    normalized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # Stop words removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in normalized_tokens if token not in stop_words]\n",
    "\n",
    "    return filtered_tokens\n",
    "\n",
    "# Function to create embeddings\n",
    "def create_embeddings(sentences):\n",
    "    model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "    return model\n",
    "\n",
    "# Function to do padding\n",
    "def pad_or_truncate_sequences(sequences, fixed_length, vector_size):\n",
    "    # Initialize a zero-filled 3D array: number of sequences x fixed_length x vector_size\n",
    "    adjusted_sequences = np.zeros((len(sequences), fixed_length, vector_size))\n",
    "    \n",
    "    for i, sequence in enumerate(sequences):\n",
    "        sequence_length = len(sequence)\n",
    "        if sequence_length > fixed_length:\n",
    "            # Truncate the sequence\n",
    "            adjusted_sequences[i, :, :] = np.array(sequence[:fixed_length])\n",
    "        else:\n",
    "            # Pad the sequence with zeros\n",
    "            adjusted_sequences[i, :sequence_length, :] = np.array(sequence)\n",
    "    \n",
    "    return adjusted_sequences\n",
    "\n",
    "# Custom Neural Network Model\n",
    "class SentimentAnalysisModel_global(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SentimentAnalysisModel_global, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 2)\n",
    "        self.fc2 = nn.Linear(2, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        # Replace BatchNorm with GroupNorm\n",
    "        self.groupnorm = nn.GroupNorm(1, 2)  # GroupNorm with 1 group and 2 channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        # x = self.batchnorm(x)\n",
    "        x = self.groupnorm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def submodel_one(global_parameters_path, df_input):\n",
    "    # Step 1: Check and balance dataset\n",
    "    df = balance_dataset(df_input)\n",
    "\n",
    "    # Step 2: Preprocess text data\n",
    "    df['processed_caption'] = df['Caption'].apply(preprocess_text)\n",
    "    sentences = df['processed_caption'].tolist()\n",
    "    word2vec_model = create_embeddings(sentences)\n",
    "\n",
    "    vectorized_sentences = [[word2vec_model.wv[word] for word in sentence if word in word2vec_model.wv] for sentence in sentences]\n",
    "\n",
    "    # Adjusting sequences to the fixed input size of 100\n",
    "    # Assuming each word vector from Word2Vec is of size 100\n",
    "    vector_size = 100\n",
    "    fixed_input_size = 100\n",
    "    modified_input_size = fixed_input_size * vector_size  # 10000\n",
    "    adjusted_sequences = pad_or_truncate_sequences(vectorized_sentences, fixed_input_size, vector_size)\n",
    "\n",
    "    # Flatten the sequences for input to the neural network\n",
    "    adjusted_sequences = adjusted_sequences.reshape(len(adjusted_sequences), -1)\n",
    "\n",
    "    # Convert target variable to numerical format\n",
    "    target = pd.get_dummies(df['Sentiment']).values\n",
    "\n",
    "    # Split dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(adjusted_sequences, target, test_size=0.25, random_state=33)\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "    # DataLoader\n",
    "    train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_data, batch_size=64)\n",
    "\n",
    "    # Load model with pretrained parameters\n",
    "    model = SentimentAnalysisModel_global(input_size=modified_input_size)\n",
    "    model.load_state_dict(torch.load(global_parameters_path))\n",
    "    model.train()\n",
    "\n",
    "    # Step 3: Train model with differential privacy\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    privacy_engine = PrivacyEngine()\n",
    "    model, optimizer, train_loader = privacy_engine.make_private(\n",
    "        module=model,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=train_loader,\n",
    "        noise_multiplier=1.0,\n",
    "        max_grad_norm=1.0\n",
    "    )\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(10):\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Return updated model parameters\n",
    "    return model.state_dict()\n",
    "\n",
    "# Example usage\n",
    "updated_parameters = submodel_one('global_parameters.pt', node1_df)\n",
    "updated_parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of the object: <class 'collections.OrderedDict'>\n",
      "Shape of _module.fc1.weight: torch.Size([2, 6])\n",
      "Shape of _module.fc1.bias: torch.Size([2])\n",
      "Shape of _module.fc2.weight: torch.Size([3, 2])\n",
      "Shape of _module.fc2.bias: torch.Size([3])\n",
      "Shape of _module.groupnorm.weight: torch.Size([2])\n",
      "Shape of _module.groupnorm.bias: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# To check the type of object and the dimensions of (an example of) updated_parameters\n",
    "\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "\n",
    "# Assuming your OrderedDict object is named updated_parameters\n",
    "updated_parameters = OrderedDict([\n",
    "    ('_module.fc1.weight', torch.tensor([[ 0.3400,  0.1648, -0.0120, 0.2103,  0.2675,  0.1745], [ 0.2891,  0.2614, -0.1232, -0.0202,  0.5096,  0.6269]])),\n",
    "    ('_module.fc1.bias', torch.tensor([-0.1213,  0.3632])),\n",
    "    ('_module.fc2.weight', torch.tensor([[ 0.5619,  0.0126], [ 0.5260, -0.4331], [ 0.6782, -0.5148]])),\n",
    "    ('_module.fc2.bias', torch.tensor([-0.4159,  0.0047,  0.6919])),\n",
    "    ('_module.groupnorm.weight', torch.tensor([0.6429, 1.2070])),\n",
    "    ('_module.groupnorm.bias', torch.tensor([ 0.2980, -0.3828]))\n",
    "])\n",
    "\n",
    "# Get the type of the object\n",
    "object_type = type(updated_parameters)\n",
    "print(f\"Type of the object: {object_type}\")\n",
    "\n",
    "# Iterate through the OrderedDict and print the shape of each tensor\n",
    "for key, tensor in updated_parameters.items():\n",
    "    print(f\"Shape of {key}: {tensor.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ie. the object above is an OrderedDict object which contains PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint on how to combine multiple OrderedDict objects\n",
    "\n",
    "# To combine the two different OrderedDict objects into a single list or array, you can simply iterate \n",
    "# over both OrderedDict objects and append their elements to a list. Since each element in the OrderedDict \n",
    "# is a key-value pair (where the key is a string and the value is a PyTorch tensor), you can store each pair \n",
    "# as a tuple within the list.\n",
    "\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "\n",
    "# First OrderedDict object\n",
    "model_parameters1 = OrderedDict([\n",
    "    ('_module.fc1.weight', torch.tensor([[ 0.3400,  0.1648, -0.0120,  0.2103,  0.2675,  0.1745],\n",
    "                                         [ 0.2891,  0.2614, -0.1232, -0.0202,  0.5096,  0.6269]])),\n",
    "    ('_module.fc1.bias', torch.tensor([-0.1213,  0.3632])),\n",
    "    ('_module.fc2.weight', torch.tensor([[ 0.5619,  0.0126],\n",
    "                                         [ 0.5260, -0.4331],\n",
    "                                         [ 0.6782, -0.5148]])),\n",
    "    ('_module.fc2.bias', torch.tensor([-0.4159,  0.0047,  0.6919])),\n",
    "    ('_module.groupnorm.weight', torch.tensor([0.6429, 1.2070])),\n",
    "    ('_module.groupnorm.bias', torch.tensor([ 0.2980, -0.3828]))\n",
    "])\n",
    "\n",
    "# Second OrderedDict object\n",
    "model_parameters2 = OrderedDict([\n",
    "    ('_module.fc1.weight', torch.tensor([[ 0.3462,  0.1719, -0.0215,  0.2117,  0.2747,  0.1678],\n",
    "                                         [ 0.3037,  0.2656, -0.1243, -0.0284,  0.5138,  0.6400]])),\n",
    "    ('_module.fc1.bias', torch.tensor([-0.2414,  0.3605])),\n",
    "    ('_module.fc2.weight', torch.tensor([[-0.4925, -0.2702],\n",
    "                                         [ 0.0939, -0.7728],\n",
    "                                         [ 0.0884, -0.3885]])),\n",
    "    ('_module.fc2.bias', torch.tensor([-0.3595,  0.0375,  0.5166])),\n",
    "    ('_module.groupnorm.weight', torch.tensor([0.7792, 1.2446])),\n",
    "    ('_module.groupnorm.bias', torch.tensor([-0.1800, -0.4572]))\n",
    "])\n",
    "\n",
    "# Combining both OrderedDict objects into one list\n",
    "combined_list = [model_parameters1, model_parameters2]\n",
    "\n",
    "# If you want an array, you can use numpy to convert the list to an array\n",
    "# import numpy as np\n",
    "# combined_array = np.array(combined_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('_module.fc1.weight',\n",
       "               tensor([[ 0.3400,  0.1648, -0.0120,  0.2103,  0.2675,  0.1745],\n",
       "                       [ 0.2891,  0.2614, -0.1232, -0.0202,  0.5096,  0.6269]])),\n",
       "              ('_module.fc1.bias', tensor([-0.1213,  0.3632])),\n",
       "              ('_module.fc2.weight',\n",
       "               tensor([[ 0.5619,  0.0126],\n",
       "                       [ 0.5260, -0.4331],\n",
       "                       [ 0.6782, -0.5148]])),\n",
       "              ('_module.fc2.bias', tensor([-0.4159,  0.0047,  0.6919])),\n",
       "              ('_module.groupnorm.weight', tensor([0.6429, 1.2070])),\n",
       "              ('_module.groupnorm.bias', tensor([ 0.2980, -0.3828]))]),\n",
       " OrderedDict([('_module.fc1.weight',\n",
       "               tensor([[ 0.3462,  0.1719, -0.0215,  0.2117,  0.2747,  0.1678],\n",
       "                       [ 0.3037,  0.2656, -0.1243, -0.0284,  0.5138,  0.6400]])),\n",
       "              ('_module.fc1.bias', tensor([-0.2414,  0.3605])),\n",
       "              ('_module.fc2.weight',\n",
       "               tensor([[-0.4925, -0.2702],\n",
       "                       [ 0.0939, -0.7728],\n",
       "                       [ 0.0884, -0.3885]])),\n",
       "              ('_module.fc2.bias', tensor([-0.3595,  0.0375,  0.5166])),\n",
       "              ('_module.groupnorm.weight', tensor([0.7792, 1.2446])),\n",
       "              ('_module.groupnorm.bias', tensor([-0.1800, -0.4572]))])]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of the outer object: <class 'list'>\n",
      "Key: _module.fc1.weight, Shape: torch.Size([2, 6])\n",
      "Key: _module.fc1.bias, Shape: torch.Size([2])\n",
      "Key: _module.fc2.weight, Shape: torch.Size([3, 2])\n",
      "Key: _module.fc2.bias, Shape: torch.Size([3])\n",
      "Key: _module.groupnorm.weight, Shape: torch.Size([2])\n",
      "Key: _module.groupnorm.bias, Shape: torch.Size([2])\n",
      "Key: _module.fc1.weight, Shape: torch.Size([2, 6])\n",
      "Key: _module.fc1.bias, Shape: torch.Size([2])\n",
      "Key: _module.fc2.weight, Shape: torch.Size([3, 2])\n",
      "Key: _module.fc2.bias, Shape: torch.Size([3])\n",
      "Key: _module.groupnorm.weight, Shape: torch.Size([2])\n",
      "Key: _module.groupnorm.bias, Shape: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Print the type of the outer object\n",
    "print(\"Type of the outer object:\", type(combined_list))\n",
    "\n",
    "# Iterate through each OrderedDict's key-value pairs\n",
    "for od in combined_list:\n",
    "    for key, tensor in od.items():\n",
    "        print(f\"Key: {key}, Shape: {tensor.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
