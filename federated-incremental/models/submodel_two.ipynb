{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING CODE WITH 5 CLIENTS, SINCE THERE ARE CALCULATIONS INVOLVING PERCENTILES\n",
    "\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "\n",
    "# First OrderedDict object\n",
    "model_parameters1 = OrderedDict([\n",
    "    ('_module.fc1.weight', torch.tensor([[ 0.3400,  0.1648, -0.0120,  0.2103,  0.2675,  0.1745],\n",
    "                                         [ 0.2891,  0.2614, -0.1232, -0.0202,  0.5096,  0.6269]])),\n",
    "    ('_module.fc1.bias', torch.tensor([-0.1213,  0.3632])),\n",
    "    ('_module.fc2.weight', torch.tensor([[ 0.5619,  0.0126],\n",
    "                                         [ 0.5260, -0.4331],\n",
    "                                         [ 0.6782, -0.5148]])),\n",
    "    ('_module.fc2.bias', torch.tensor([-0.4159,  0.0047,  0.6919])),\n",
    "    ('_module.groupnorm.weight', torch.tensor([0.6429, 1.2070])),\n",
    "    ('_module.groupnorm.bias', torch.tensor([ 0.2980, -0.3828]))\n",
    "])\n",
    "\n",
    "# Second OrderedDict object\n",
    "model_parameters2 = OrderedDict([\n",
    "    ('_module.fc1.weight', torch.tensor([[ 0.3462,  0.1719, -0.0215,  0.2117,  0.2747,  0.1678],\n",
    "                                         [ 0.3037,  0.2656, -0.1243, -0.0284,  0.5138,  0.6400]])),\n",
    "    ('_module.fc1.bias', torch.tensor([-0.2414,  0.3605])),\n",
    "    ('_module.fc2.weight', torch.tensor([[-0.4925, -0.2702],\n",
    "                                         [ 0.0939, -0.7728],\n",
    "                                         [ 0.0884, -0.3885]])),\n",
    "    ('_module.fc2.bias', torch.tensor([-0.3595,  0.0375,  0.5166])),\n",
    "    ('_module.groupnorm.weight', torch.tensor([0.7792, 1.2446])),\n",
    "    ('_module.groupnorm.bias', torch.tensor([-0.1800, -0.4572]))\n",
    "])\n",
    "\n",
    "# Third OrderedDict object\n",
    "model_parameters3 = OrderedDict([\n",
    "    ('_module.fc1.weight', torch.tensor([[ 0.3500,  0.1748, -0.0220,  0.2203,  0.2775,  0.1845],\n",
    "                                         [ 0.2991,  0.2714, -0.1332, -0.0302,  0.5196,  0.6369]])),\n",
    "    ('_module.fc1.bias', torch.tensor([-0.1313,  0.3732])),\n",
    "    ('_module.fc2.weight', torch.tensor([[ 0.5719,  0.0226],\n",
    "                                         [ 0.5360, -0.4431],\n",
    "                                         [ 0.6882, -0.5248]])),\n",
    "    ('_module.fc2.bias', torch.tensor([-0.4259,  0.0147,  0.7019])),\n",
    "    ('_module.groupnorm.weight', torch.tensor([0.6529, 1.2170])),\n",
    "    ('_module.groupnorm.bias', torch.tensor([ 0.3080, -0.3928]))\n",
    "])\n",
    "\n",
    "# Fourth OrderedDict object\n",
    "model_parameters4 = OrderedDict([\n",
    "    ('_module.fc1.weight', torch.tensor([[ 0.3600,  0.1848, -0.0320,  0.2303,  0.2875,  0.1945],\n",
    "                                         [ 0.3091,  0.2814, -0.1432, -0.0402,  0.5296,  0.6469]])),\n",
    "    ('_module.fc1.bias', torch.tensor([-0.1413,  0.3832])),\n",
    "    ('_module.fc2.weight', torch.tensor([[ 0.5819,  0.0326],\n",
    "                                         [ 0.5460, -0.4531],\n",
    "                                         [ 0.6982, -0.5348]])),\n",
    "    ('_module.fc2.bias', torch.tensor([-0.4359,  0.0247,  0.7119])),\n",
    "    ('_module.groupnorm.weight', torch.tensor([0.6629, 1.2270])),\n",
    "    ('_module.groupnorm.bias', torch.tensor([ 0.3180, -0.4028]))\n",
    "])\n",
    "\n",
    "# Fifth OrderedDict object\n",
    "model_parameters5 = OrderedDict([\n",
    "    ('_module.fc1.weight', torch.tensor([[ 0.3700,  0.1948, -0.0420,  0.2403,  0.2975,  0.2045],\n",
    "                                         [ 0.3191,  0.2914, -0.1532, -0.0502,  0.5396,  0.6569]])),\n",
    "    ('_module.fc1.bias', torch.tensor([-0.1513,  0.3932])),\n",
    "    ('_module.fc2.weight', torch.tensor([[ 0.5919,  0.0426],\n",
    "                                         [ 0.5560, -0.4631],\n",
    "                                         [ 0.7082, -0.5448]])),\n",
    "    ('_module.fc2.bias', torch.tensor([-0.4459,  0.0347,  0.7219])),\n",
    "    ('_module.groupnorm.weight', torch.tensor([0.6729, 1.2370])),\n",
    "    ('_module.groupnorm.bias', torch.tensor([ 0.3280, -0.4128]))\n",
    "])\n",
    "\n",
    "# Combine all OrderedDict objects into a list of tuples\n",
    "combined_list = [model_parameters1, model_parameters2, model_parameters3, model_parameters4, model_parameters5]\n",
    "\n",
    "# If you want an array, you can use numpy to convert the list to an array\n",
    "# import numpy as np\n",
    "# combined_array = np.array(combined_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('_module.fc1.weight',\n",
       "               tensor([[ 0.3400,  0.1648, -0.0120,  0.2103,  0.2675,  0.1745],\n",
       "                       [ 0.2891,  0.2614, -0.1232, -0.0202,  0.5096,  0.6269]])),\n",
       "              ('_module.fc1.bias', tensor([-0.1213,  0.3632])),\n",
       "              ('_module.fc2.weight',\n",
       "               tensor([[ 0.5619,  0.0126],\n",
       "                       [ 0.5260, -0.4331],\n",
       "                       [ 0.6782, -0.5148]])),\n",
       "              ('_module.fc2.bias', tensor([-0.4159,  0.0047,  0.6919])),\n",
       "              ('_module.groupnorm.weight', tensor([0.6429, 1.2070])),\n",
       "              ('_module.groupnorm.bias', tensor([ 0.2980, -0.3828]))]),\n",
       " OrderedDict([('_module.fc1.weight',\n",
       "               tensor([[ 0.3462,  0.1719, -0.0215,  0.2117,  0.2747,  0.1678],\n",
       "                       [ 0.3037,  0.2656, -0.1243, -0.0284,  0.5138,  0.6400]])),\n",
       "              ('_module.fc1.bias', tensor([-0.2414,  0.3605])),\n",
       "              ('_module.fc2.weight',\n",
       "               tensor([[-0.4925, -0.2702],\n",
       "                       [ 0.0939, -0.7728],\n",
       "                       [ 0.0884, -0.3885]])),\n",
       "              ('_module.fc2.bias', tensor([-0.3595,  0.0375,  0.5166])),\n",
       "              ('_module.groupnorm.weight', tensor([0.7792, 1.2446])),\n",
       "              ('_module.groupnorm.bias', tensor([-0.1800, -0.4572]))]),\n",
       " OrderedDict([('_module.fc1.weight',\n",
       "               tensor([[ 0.3500,  0.1748, -0.0220,  0.2203,  0.2775,  0.1845],\n",
       "                       [ 0.2991,  0.2714, -0.1332, -0.0302,  0.5196,  0.6369]])),\n",
       "              ('_module.fc1.bias', tensor([-0.1313,  0.3732])),\n",
       "              ('_module.fc2.weight',\n",
       "               tensor([[ 0.5719,  0.0226],\n",
       "                       [ 0.5360, -0.4431],\n",
       "                       [ 0.6882, -0.5248]])),\n",
       "              ('_module.fc2.bias', tensor([-0.4259,  0.0147,  0.7019])),\n",
       "              ('_module.groupnorm.weight', tensor([0.6529, 1.2170])),\n",
       "              ('_module.groupnorm.bias', tensor([ 0.3080, -0.3928]))]),\n",
       " OrderedDict([('_module.fc1.weight',\n",
       "               tensor([[ 0.3600,  0.1848, -0.0320,  0.2303,  0.2875,  0.1945],\n",
       "                       [ 0.3091,  0.2814, -0.1432, -0.0402,  0.5296,  0.6469]])),\n",
       "              ('_module.fc1.bias', tensor([-0.1413,  0.3832])),\n",
       "              ('_module.fc2.weight',\n",
       "               tensor([[ 0.5819,  0.0326],\n",
       "                       [ 0.5460, -0.4531],\n",
       "                       [ 0.6982, -0.5348]])),\n",
       "              ('_module.fc2.bias', tensor([-0.4359,  0.0247,  0.7119])),\n",
       "              ('_module.groupnorm.weight', tensor([0.6629, 1.2270])),\n",
       "              ('_module.groupnorm.bias', tensor([ 0.3180, -0.4028]))]),\n",
       " OrderedDict([('_module.fc1.weight',\n",
       "               tensor([[ 0.3700,  0.1948, -0.0420,  0.2403,  0.2975,  0.2045],\n",
       "                       [ 0.3191,  0.2914, -0.1532, -0.0502,  0.5396,  0.6569]])),\n",
       "              ('_module.fc1.bias', tensor([-0.1513,  0.3932])),\n",
       "              ('_module.fc2.weight',\n",
       "               tensor([[ 0.5919,  0.0426],\n",
       "                       [ 0.5560, -0.4631],\n",
       "                       [ 0.7082, -0.5448]])),\n",
       "              ('_module.fc2.bias', tensor([-0.4459,  0.0347,  0.7219])),\n",
       "              ('_module.groupnorm.weight', tensor([0.6729, 1.2370])),\n",
       "              ('_module.groupnorm.bias', tensor([ 0.3280, -0.4128]))])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "from typing import List\n",
    "\n",
    "def submodel_two(models: List[OrderedDict]) -> OrderedDict:\n",
    "    # Helper function to calculate IQR-based non-outliers for a list of values\n",
    "    def non_outlier_values(values):\n",
    "        q1, q3 = torch.quantile(torch.tensor(values), torch.tensor([0.25, 0.75]))\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "        return [v for v in values if v >= lower_bound and v <= upper_bound]\n",
    "\n",
    "    # Initialize a dictionary to store sums and counts for averaging\n",
    "    sums = OrderedDict((key, torch.zeros_like(models[0][key])) for key in models[0])\n",
    "    counts = OrderedDict((key, torch.zeros_like(models[0][key])) for key in models[0])\n",
    "\n",
    "    # Iterate through each key and each element in the tensors\n",
    "    for key in models[0].keys():\n",
    "        for i in range(models[0][key].numel()):\n",
    "            # Extract the same element from all models\n",
    "            values = [model[key].view(-1)[i].item() for model in models]\n",
    "\n",
    "            # Calculate non-outlier values\n",
    "            non_outliers = non_outlier_values(values)\n",
    "\n",
    "            # Update sums and counts\n",
    "            if non_outliers:\n",
    "                sums[key].view(-1)[i] = sum(non_outliers)\n",
    "                counts[key].view(-1)[i] = len(non_outliers)\n",
    "\n",
    "    # Calculate element-wise averages for non-outliers and remove the '_module' prefix\n",
    "    averages = OrderedDict()\n",
    "    for key in sums.keys():\n",
    "        new_key = key.replace('_module.', '')  # Remove '_module.' prefix\n",
    "        with torch.no_grad():  # Ensure no gradient is computed during division\n",
    "            averages[new_key] = sums[key] / counts[key].clamp(min=1)  # Avoid division by zero\n",
    "\n",
    "    return averages\n",
    "\n",
    "averaged_values = submodel_two(combined_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[ 0.3532,  0.1782, -0.0259,  0.2226,  0.2809,  0.1852],\n",
       "                      [ 0.3040,  0.2742, -0.1354, -0.0338,  0.5224,  0.6415]])),\n",
       "             ('fc1.bias', tensor([-0.1363,  0.3747])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 0.5769,  0.0276],\n",
       "                      [ 0.5410, -0.4481],\n",
       "                      [ 0.6932, -0.5298]])),\n",
       "             ('fc2.bias', tensor([-0.4309,  0.0233,  0.7069])),\n",
       "             ('groupnorm.weight', tensor([0.6579, 1.2265])),\n",
       "             ('groupnorm.bias', tensor([ 0.3130, -0.3978]))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaged_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING CODE WITH 2 CLIENTS, SINCE THERE ARE CALCULATIONS INVOLVING PERCENTILES\n",
    "\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "\n",
    "# First OrderedDict object\n",
    "model_parameters1 = OrderedDict([\n",
    "    ('_module.fc1.weight', torch.tensor([[ 0.3400,  0.1648, -0.0120,  0.2103,  0.2675,  0.1745],\n",
    "                                         [ 0.2891,  0.2614, -0.1232, -0.0202,  0.5096,  0.6269]])),\n",
    "    ('_module.fc1.bias', torch.tensor([-0.1213,  0.3632])),\n",
    "    ('_module.fc2.weight', torch.tensor([[ 0.5619,  0.0126],\n",
    "                                         [ 0.5260, -0.4331],\n",
    "                                         [ 0.6782, -0.5148]])),\n",
    "    ('_module.fc2.bias', torch.tensor([-0.4159,  0.0047,  0.6919])),\n",
    "    ('_module.groupnorm.weight', torch.tensor([0.6429, 1.2070])),\n",
    "    ('_module.groupnorm.bias', torch.tensor([ 0.2980, -0.3828]))\n",
    "])\n",
    "\n",
    "# Second OrderedDict object\n",
    "model_parameters2 = OrderedDict([\n",
    "    ('_module.fc1.weight', torch.tensor([[ 0.3462,  0.1719, -0.0215,  0.2117,  0.2747,  0.1678],\n",
    "                                         [ 0.3037,  0.2656, -0.1243, -0.0284,  0.5138,  0.6400]])),\n",
    "    ('_module.fc1.bias', torch.tensor([-0.2414,  0.3605])),\n",
    "    ('_module.fc2.weight', torch.tensor([[-0.4925, -0.2702],\n",
    "                                         [ 0.0939, -0.7728],\n",
    "                                         [ 0.0884, -0.3885]])),\n",
    "    ('_module.fc2.bias', torch.tensor([-0.3595,  0.0375,  0.5166])),\n",
    "    ('_module.groupnorm.weight', torch.tensor([0.7792, 1.2446])),\n",
    "    ('_module.groupnorm.bias', torch.tensor([-0.1800, -0.4572]))\n",
    "])\n",
    "\n",
    "# Combine all OrderedDict objects into a list of tuples\n",
    "combined_list = [model_parameters1, model_parameters2]\n",
    "\n",
    "# If you want an array, you can use numpy to convert the list to an array\n",
    "# import numpy as np\n",
    "# combined_array = np.array(combined_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('_module.fc1.weight',\n",
       "               tensor([[ 0.3400,  0.1648, -0.0120,  0.2103,  0.2675,  0.1745],\n",
       "                       [ 0.2891,  0.2614, -0.1232, -0.0202,  0.5096,  0.6269]])),\n",
       "              ('_module.fc1.bias', tensor([-0.1213,  0.3632])),\n",
       "              ('_module.fc2.weight',\n",
       "               tensor([[ 0.5619,  0.0126],\n",
       "                       [ 0.5260, -0.4331],\n",
       "                       [ 0.6782, -0.5148]])),\n",
       "              ('_module.fc2.bias', tensor([-0.4159,  0.0047,  0.6919])),\n",
       "              ('_module.groupnorm.weight', tensor([0.6429, 1.2070])),\n",
       "              ('_module.groupnorm.bias', tensor([ 0.2980, -0.3828]))]),\n",
       " OrderedDict([('_module.fc1.weight',\n",
       "               tensor([[ 0.3462,  0.1719, -0.0215,  0.2117,  0.2747,  0.1678],\n",
       "                       [ 0.3037,  0.2656, -0.1243, -0.0284,  0.5138,  0.6400]])),\n",
       "              ('_module.fc1.bias', tensor([-0.2414,  0.3605])),\n",
       "              ('_module.fc2.weight',\n",
       "               tensor([[-0.4925, -0.2702],\n",
       "                       [ 0.0939, -0.7728],\n",
       "                       [ 0.0884, -0.3885]])),\n",
       "              ('_module.fc2.bias', tensor([-0.3595,  0.0375,  0.5166])),\n",
       "              ('_module.groupnorm.weight', tensor([0.7792, 1.2446])),\n",
       "              ('_module.groupnorm.bias', tensor([-0.1800, -0.4572]))])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "from typing import List\n",
    "\n",
    "def submodel_two(models: List[OrderedDict]) -> OrderedDict:\n",
    "    # Helper function to calculate IQR-based non-outliers for a list of values\n",
    "    def non_outlier_values(values):\n",
    "        q1, q3 = torch.quantile(torch.tensor(values), torch.tensor([0.25, 0.75]))\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "        return [v for v in values if v >= lower_bound and v <= upper_bound]\n",
    "\n",
    "    # Initialize a dictionary to store sums and counts for averaging\n",
    "    sums = OrderedDict((key, torch.zeros_like(models[0][key])) for key in models[0])\n",
    "    counts = OrderedDict((key, torch.zeros_like(models[0][key])) for key in models[0])\n",
    "\n",
    "    # Iterate through each key and each element in the tensors\n",
    "    for key in models[0].keys():\n",
    "        for i in range(models[0][key].numel()):\n",
    "            # Extract the same element from all models\n",
    "            values = [model[key].view(-1)[i].item() for model in models]\n",
    "\n",
    "            # Calculate non-outlier values\n",
    "            non_outliers = non_outlier_values(values)\n",
    "\n",
    "            # Update sums and counts\n",
    "            if non_outliers:\n",
    "                sums[key].view(-1)[i] = sum(non_outliers)\n",
    "                counts[key].view(-1)[i] = len(non_outliers)\n",
    "\n",
    "    # Calculate element-wise averages for non-outliers and remove the '_module' prefix\n",
    "    averages = OrderedDict()\n",
    "    for key in sums.keys():\n",
    "        new_key = key.replace('_module.', '')  # Remove '_module.' prefix\n",
    "        with torch.no_grad():  # Ensure no gradient is computed during division\n",
    "            averages[new_key] = sums[key] / counts[key].clamp(min=1)  # Avoid division by zero\n",
    "\n",
    "    return averages\n",
    "\n",
    "averaged_values = submodel_two(combined_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[ 0.3431,  0.1684, -0.0168,  0.2110,  0.2711,  0.1711],\n",
       "                      [ 0.2964,  0.2635, -0.1238, -0.0243,  0.5117,  0.6335]])),\n",
       "             ('fc1.bias', tensor([-0.1813,  0.3619])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 0.0347, -0.1288],\n",
       "                      [ 0.3100, -0.6029],\n",
       "                      [ 0.3833, -0.4517]])),\n",
       "             ('fc2.bias', tensor([-0.3877,  0.0211,  0.6043])),\n",
       "             ('groupnorm.weight', tensor([0.7111, 1.2258])),\n",
       "             ('groupnorm.bias', tensor([ 0.0590, -0.4200]))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaged_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING CODE ON 5 OR 2 CLIENTS BOTH WORKED!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
