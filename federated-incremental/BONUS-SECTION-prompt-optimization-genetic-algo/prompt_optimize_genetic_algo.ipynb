{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import nltk  # Natural Language Toolkit\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize Llama2 model from Hugging Face\n",
    "llama2 = pipeline('text-generation', model='EleutherAI/gpt-neo-2.7B')\n",
    "\n",
    "# Initialize sentence transformer model for embedding\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Task Definition - Here's a general task for creative writing\n",
    "task = \"Write a short story about a lost kitten\"\n",
    "\n",
    "# Initial Population\n",
    "initial_population_size = 50\n",
    "population = [llama2(task, max_length=50, do_sample=True)[0]['generated_text'] for _ in range(initial_population_size)]\n",
    "\n",
    "def dot_product_similarity(text1, text2):\n",
    "    # Generate embeddings for each text\n",
    "    embedding1 = model.encode(text1)\n",
    "    embedding2 = model.encode(text2)\n",
    "    \n",
    "    # Compute the dot product of the two embeddings\n",
    "    similarity = np.dot(embedding1, embedding2) / (np.linalg.norm(embedding1) * np.linalg.norm(embedding2))\n",
    "    return similarity\n",
    "\n",
    "# Fitness Function\n",
    "def fitness(prompt, desired_output):\n",
    "    generated_output = llama2(prompt, max_length=50)[0]['generated_text']\n",
    "    # Using dot product similarity between embeddings for fitness\n",
    "    return dot_product_similarity(generated_output, desired_output)\n",
    "\n",
    "# Crossover Operation\n",
    "def crossover(parent1, parent2):\n",
    "    # Simple one-point crossover\n",
    "    point = random.randint(1, min(len(parent1), len(parent2)) - 1)\n",
    "    child1 = parent1[:point] + parent2[point:]\n",
    "    child2 = parent2[:point] + parent1[point:]\n",
    "    return ' '.join(child1), ' '.join(child2)\n",
    "\n",
    "# Function to tokenize and represent prompts as a list of words\n",
    "def represent_prompt(prompt):\n",
    "    return word_tokenize(prompt)\n",
    "\n",
    "# Mutation Operation\n",
    "def mutate_prompt(prompt):\n",
    "    words = represent_prompt(prompt)\n",
    "    if words:\n",
    "        idx = random.randint(0, len(words) - 1)\n",
    "        words[idx] = \"adventure\"  # changing a random word; you might want to select more sensibly\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Selection Strategy\n",
    "def select_population(population, desired_output):\n",
    "    scored_population = [(prompt, fitness(prompt, desired_output)) for prompt in population]\n",
    "    scored_population.sort(key=lambda x: x[1])  # Lower edit distance is better\n",
    "    return [prompt for prompt, _ in scored_population[:initial_population_size]]\n",
    "\n",
    "# Evolution Function\n",
    "def evolve_population(population, desired_output):\n",
    "    new_population = select_population(population, desired_output)\n",
    "    while len(new_population) < len(population):\n",
    "        parent1, parent2 = random.sample(new_population, 2)\n",
    "        child1, child2 = crossover(represent_prompt(parent1), represent_prompt(parent2))\n",
    "        new_population += [child1, child2]\n",
    "    return [mutate_prompt(prompt) for prompt in new_population]\n",
    "\n",
    "# Desired Output for the Task - This should be a specific example of a good output\n",
    "desired_output = \"Once upon a time, there was a small kitten named Whiskers who was lost in a big, dark forest.\"\n",
    "\n",
    "# Run the genetic algorithm for a number of generations\n",
    "generations = 20  # Number of generations\n",
    "for _ in range(generations):\n",
    "    population = evolve_population(population, desired_output)\n",
    "\n",
    "# Select the best prompt\n",
    "best_prompt = select_population(population, desired_output)[0]\n",
    "print(\"Best prompt found:\", best_prompt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
